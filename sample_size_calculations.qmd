---
title: "Sample Size Calculations"
format: html
editor: visual
---

## Sample Size calculations

We are interested in calculating the sample required to estimate a a minimal detectable effect of 0.4 between the household survey and the network survival method. Note: we making a series of assumptions for our power size calculations.

## Analytic Sample size calculations 

$$
 e^2_0 = (1.96^2)V(\hat{p}) = (1.96^2) \frac{p}{n\bar{d}} \\
\leftrightarrow n = (1.96^2) \frac{p}{e^2_0 \bar{d}} \\ 
$$

-   p = 0.02

-   d = 50

-   e_0 = 0.4

```{r}
library(tidyverse)
library(data.table)
```

```{r}
## filter out health professional 
formative_survey <- formative_survey %>% 
  filter(job != "Professionnel de la sant√©" & deaths_3month <= 5)
```

```{r}
## estimate from formative survey 
formative_survey %>% 
  summarize(total_deaths = mean(deaths_3month), total_network = mean(network_talk_weekly)) %>% 
  mutate(rate = total_deaths / total_network,
         rate_daily =  total_deaths / total_network / 90 * 10000) 

```

```{r}
## sample size calculations with bootstrap 
interval_list <- list()

for (sample in seq(100, 1000, by = 100)) {

resample <- list()

for (i in 1:1000) {
resample[[i]] <- formative_survey %>% 
  sample_n(replace = T, size = sample) %>% 
  summarize(num = mean(deaths_3month, na.rm = T),
            denom = mean(network_talk_weekly, na.rm = T)) %>% 
  mutate(estimate = num / denom) 
}

interval_list[[sample]] <- bind_rows(resample) %>% 
  mutate(estimate_emergency = estimate / 90 * 10000) %>% 
  summarize(lower = quantile(estimate_emergency, 0.025),
            upper = quantile(estimate_emergency, 0.975),
            mean = mean(estimate_emergency)) %>% 
  mutate(sample_size = sample)

cat(sample)
} 

intervals_sample_size <- bind_rows(interval_list) 
```

```{intervals_sample_size}
```

```{r}
## calculate intervals 
sample_sizes <- seq(100, 1000, by = 100)
e0_analytic_calc = sqrt(1.96^2 * 2.7/100/(sample_sizes * 50)) * 100

## sample size calculations 
intervals_sample_size <- intervals_sample_size %>% 
  mutate(e0 = (upper - lower)/2) %>% 
  mutate(e0_analytic = e0_analytic_calc)

intervals_sample_size_long <- intervals_sample_size %>% 
  select(sample_size, e0, e0_analytic) %>% 
  pivot_longer(-sample_size)

## sample size intervals 
intervals_sample_size_long %>% 
  ggplot() + 
  geom_line(aes(x = sample_size, value, color = name), size = 1.3) + 
  cowplot::theme_cowplot() + 
  ylim(0, 1) + 
  ggsci::scale_color_lancet() + 
  theme(legend.position = "bottom") + 
  labs(x = "Sample Size",
       y = "Coefficient of Variation",
       title = "Variance Estimation")
```

## Minimum detectable effect size 

The minimum detectable effect size is the largest effect size we are able to detect.

## Sample Size calculation 1

Goal: produce an estimate for a 3-month period with a standard error small enough so that if the underlying crude death rate changes in the next 3-month period, and the measurement is taken again in exactly the same way, we'd be able to detect a difference of 0.4 per 10,000 / day.

For the household survey, we will calculate estimated level of precision at household level.

```{r}
## parameters for mortality estimation study 
households = 1074
members_per_household = 5.5
N = households * members_per_household
p = 0.87 ## deaths per day per 10000 
design_effect = 1.5 

## calculate variante 
variance = ((1 - p/100)*(p/100))/N * design_effect
sd = sqrt(variance)

## estimate 95% CI 
c(p -1.96*sd, p + 1.96*sd)*100
```

```{r}
sd_hh <- 0.001479873 * 100
sd <- 0.1811186

df <- tibble(dist1 = rnorm(mean = 3.27, sd = sd_hh, n = 100000),
             dist2 = rnorm(mean = 3.27 - 0.4, sd = sd, n = 100000))

df %>% mutate(id = 1) %>% pivot_longer(-id) %>% 
  ggplot(aes(x = value, fill = name)) + 
  geom_density(alpha = 0.2) + 
  cowplot::theme_cowplot()
```

1.  Look at Under-5
2.  Gender differences in size of network
3.  Power size calculations
4.  Look through materials
5.  Submit IRB tonight
6.  
